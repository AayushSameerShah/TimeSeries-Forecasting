{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b37fb6-ae80-4831-9f82-43fab436b04a",
   "metadata": {},
   "source": [
    "# A training of the network.\n",
    "*Going forward to explore, coming back to fix mistakes. <br> And that's the learning my friend. <br><br> ‚Äî Mind*\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"../images/forward-prop.png\" width=400 height=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d0b178-84c2-4ba7-a388-e0df7dca2380",
   "metadata": {},
   "source": [
    "## How is that built?\n",
    "A neural network is the \"stack\" of layers made up of neurons.\n",
    "\n",
    "- Each neuron is able to **capture different part** of something.\n",
    "- The **input layer** can be connected to several other neurons.\n",
    "- This can be seen as a neural network **approach** to multi-target-regression.\n",
    "\n",
    "\n",
    "<img src=\"../images/nn-capture.png\" width=400 height=500>\n",
    "\n",
    "- We can keep adding the layers and build a \"**deep**\" network.\n",
    "- There are 2 things:\n",
    "    - A network can be **deep**\n",
    "    - A network can be **wide**\n",
    "- Each layer can act as an input of another layer.\n",
    " \n",
    "<img src=\"../images/deep-wide.png\" width=400 height=500>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9767c8f1-0b29-4d1f-9d08-ea29654ea1dc",
   "metadata": {},
   "source": [
    "## üÜí A cool thing\n",
    "\n",
    "<img src=\"../images/neuron-vs-line.png\" width=400 height=500>\n",
    "\n",
    "## $$\\text{A Line} = \\beta_0 + \\beta_1x_1$$\n",
    "## $$\\text{A Neuron} = \\sigma(\\beta_0 + \\beta_1x_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13803d0d-c8ab-434b-abf9-e2f10e29293e",
   "metadata": {},
   "source": [
    "I know, repetative thing. But it is the reinforcement; right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533cb690-bbc6-4c4b-81fc-bf2a688d34ee",
   "metadata": {},
   "source": [
    "## üññ In a math language?\n",
    "That \"$\\text{A Neuron}$\" is just for the single computation of the neuron. But how about a whole network? How can we go for computing all nodes? Multiple calculations?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01bcb05-0ab0-4dbe-b4fa-96a3f20d03b7",
   "metadata": {},
   "source": [
    "## $$z_j  = \\sigma(w_j^Tx + b_j)$$\n",
    "\n",
    "For, $j: 1, 2, 3, \\cdots, M$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d80f86f-fbab-4fa4-b41a-a5dd7d2b0412",
   "metadata": {},
   "source": [
    "<img src=\"../images/multiple-neurons.png\" height=400 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942dbd1f-b88e-4580-8293-10bbf88351a6",
   "metadata": {},
   "source": [
    "> **NOTE:** Here, we are using the terms $w$ and $z$ representing the \"weights\" or **coefficients** and \"output\" or **transformed output** for $\\beta_i$ and $\\hat y$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6454dda2-57ac-48f9-9e1b-f7be30f339c6",
   "metadata": {},
   "source": [
    "## ü™ë To write it more \"compactly\"\n",
    "We can make a *single* matrix for all of these.\n",
    "\n",
    "So, instead calculating things like above, we can calculate it like below to make calculation more efficient.\n",
    "\n",
    "# $$z = \\sigma(W^Tx + b)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbde834-c5a1-475b-a542-c2b626c840ee",
   "metadata": {},
   "source": [
    "## ü§ù How does that look like in the network?\n",
    "<img src=\"../images/nn-math.png\" height=400 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174256fc-cbba-498d-ab71-6301a57d18ad",
   "metadata": {},
   "source": [
    "Please pay attention, interesting notations here:\n",
    "1. $W^{(1)}:$  Is the **weight matrix** or coefficient matrix for the upcoming layer 1.\n",
    "    - Meaning as we have seen that in the *compact* form, W is a cofficient matrix. The matrix for the connections that you see in the form of a ***line***.\n",
    "    - Thus, the input will be multiplied with thaose coefs and then the result will be passed to the activation function.\n",
    "2. $b^{(1)}:$ Is also a **matrix of the intercepts**. Thus, it will be added to the $W^{(1)}$ term.\n",
    "3. $Z^{(1)}:$ Is the **output matrix**. \n",
    "    - Means, after the calculation of $W^Tx + b$ their output will be passed to the *activation function*\n",
    "    - Thus, $Z^{(1)}$ will have the result of $\\sigma(W^Tx + b)$\n",
    "\n",
    "They were **for the first layer only**. Meaning... <br>\n",
    "<img src=\"../images/nn-math-1.png\" height=400 width=500>\n",
    "\n",
    "For the upcoming second layer... <br>\n",
    "<img src=\"../images/nn-math-2.png\" height=400 width=500>\n",
    "\n",
    "The same calculation will take place. That's why the neural networks are called: **Uniform**. In all of their parts, the calculation is same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd048b72-7c27-4111-ac02-5eb5f84dc40f",
   "metadata": {},
   "source": [
    "Thus, the calculation goes like...\n",
    "\n",
    "For the first layer:<br>\n",
    "$z^{(1)} = \\sigma(W^{(1)T}x + b^{(1)})$ \n",
    "\n",
    "For the second layer:<br>\n",
    "$z^{(2)} = \\sigma(W^{(2)T}z^{(1)} + b^{(2)})$ \n",
    "\n",
    "For the third layer:<br>\n",
    "$z^{(3)} = \\sigma(W^{(3)T}z^{(2)} + b^{(3)})$ \n",
    "\n",
    "> **Note** the $z^{(1,2)}$ in the second and third layer calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed3c169-53e3-4789-aedd-58f9a88f0fb5",
   "metadata": {},
   "source": [
    "And **finally** for the final calculation... in the last output layer we have 2 options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55b2c4-fb25-406f-8da4-4d67e1e24d1a",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ For Classification\n",
    "\n",
    "Over here <br>\n",
    "<img src=\"../images/nn-math-3.png\" height=400 width=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa087def-86a9-42a4-8de8-95d2ddfb60f2",
   "metadata": {},
   "source": [
    "# $$p(y=1|x) = \\sigma(W^{(L)T}z^{(L-1)} + b^{(L)})$$\n",
    "\n",
    "Where, <br>\n",
    "$L:$ Refers to the total number of layers. Here we use `L`. But we could have used `N` for the same. But that might be ambiguous. <br>\n",
    "$W^{(L)T}:$ Is the coefficient matrix for this last output layer. <br>\n",
    "$ b^{(L)}:$ Is the intercept matrix for the last output later. <br>\n",
    "$z^{(L-1)}:$ It is used coming as the inputs from the last layer.\n",
    "\n",
    "And, we are **using the sigmoid** function **because it is the classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f6ec9d-5116-49a9-bb67-f9dbe2a03c2b",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ For Regression\n",
    "\n",
    "# $$\\hat y = W^{(L)T}z^{(L-1)} + b^{(L)}$$\n",
    "\n",
    "We will **just remove** the sigmoid from the last layer! How cool is that!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ddde7-a56a-449d-bfd3-ff9a97e5f711",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd98865-1cdd-451d-91f4-05367cff71e8",
   "metadata": {},
   "source": [
    "## A Perspective\n",
    "\n",
    "We can see that each latyer acts as **some kind of** feature transformation. Each of them transforms the feature space differently. captures different kind of features from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf74373-c432-4125-9aed-0885dc01cdcf",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f2159b-21fc-46f6-bc6e-f6a2455841b8",
   "metadata": {},
   "source": [
    "# A Great Stuff.\n",
    "It is really great to learn this \"*black box*\" and see what happens internally. Let's catch you up in the next book where we will have understanding of different **activation functions**for these black boxes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
