{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddcfde32-1e11-4283-b5d6-0b3e00585cb6",
   "metadata": {},
   "source": [
    "# üé© AIC & BIC Critarion \n",
    "What's going on...? So, we have given our data to the Auto ARIMA and it is trying to use different combinations of the parameters which goes on forever but when to stop? Any idea?\n",
    "\n",
    "Simply that leads us to the question that: **\"What is best?\"** <br>\n",
    "Define, what do you mean by **best**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69134e36-bcbc-4a52-a04a-4e8aeca348a8",
   "metadata": {},
   "source": [
    "## üë®‚Äçüî¨ ARIMA is a statistical model\n",
    "Actually every ML models is! What's new in here? Nan buddy, **ML and Stats share some common goals but they are different**. If they were the same, they would have been called the same! ML should be == Stats. But that is not.\n",
    "\n",
    "To clear my understanding on this topic, I did some initial reding on the internet and found the following findings:\n",
    "\n",
    "> *‚ÄúThe major difference between machine learning and statistics is their purpose.\"* <br>\n",
    "> <br>-  The point of making statistical models is ***to understand the relationship between the variables***.\n",
    "> <br>- For machine learning, the main aim is ***to get the best predictive accuracy and the interpretability is not concerned much***.\n",
    "\n",
    "Still I am not convinced by the explanations and they are pretty vague. Now, **the point** that I want to make is that, ARIMA is the statistical model, and so the methods to **define the \"best\"** is rooted in classic statistics.\n",
    "\n",
    "Meaning, in ML we are tend to use the \"Accuracy\", \"RMSE\" etc to compare the models, but here we don't *usually* do that, what we prefer to use is **AIC** and **BIC** scores.\n",
    "\n",
    "Yeah, those guyz who appeared for the first time when you were learning the GMM model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c068e3f5-7589-45a5-8a34-d6ddb43dad0b",
   "metadata": {},
   "source": [
    "## Both guys\n",
    "1Ô∏è‚É£ **AIC**: *Akaike Information Criterion* <br>\n",
    "2Ô∏è‚É£ **BIC**: *Bayesian Information Criterion*\n",
    "\n",
    "In machine learning we often have to make the *tred-off* between **model accuracy** and **model complexity**. \n",
    "\n",
    "- For ARIMA the **model complexity** is increasing the value of `p` and `q`.\n",
    "- So, if we add more & more terms, the model will get more & more accurate.\n",
    "- Like in *linear regression*, even if we add the completely random variable; the accuracy will still raise. \n",
    "- So **how do we know enough is enough, and not to add more variables?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193f4ec-f474-4cbf-a1d0-37a5bd326d61",
   "metadata": {},
   "source": [
    "And this is the most famous picture in the Data-science kingdom to drive my point home...\n",
    "\n",
    "<img src=\"../images/overfitting.png\" height=300 width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c46840-a9d2-484d-9be7-231f85af478e",
   "metadata": {},
   "source": [
    "## It is Log-Likelihood\n",
    "In stats, the answer is to **penalize** the model complexity.\n",
    "\n",
    "- In ARIMA models the **loss function is the log0likelihood**\n",
    "- Mostly, minimizing the log-likelihood is equivalent to minimizing the squared error\n",
    "- And **if we only look for the log-likelihood** we might **endup overfitting**. Again, said ***if only***.\n",
    "- So **we add a \"penelty\" term** to the negative log-likeli hood.\n",
    "\n",
    "> The main difference beetween AIC and BIC is that the **penelty term is computed differently**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98012d98-1e3f-4a4b-9b5c-4938d1352faa",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab63fa1-f167-4243-866f-57b9ecf31d3c",
   "metadata": {},
   "source": [
    "# üõ§Ô∏è A Great Side-Track\n",
    "*What is likelihood?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd00bad-8214-4334-be8f-e2bec7c7fe0c",
   "metadata": {},
   "source": [
    "I know that this might sound a little silly to talk about *\"what is likelihood\"* at this stage of learning, but to be frank, I have discovered many things getting clearer after a long time having spent with them already! The reason simply is because I have learnt ML in the other-way around.\n",
    "\n",
    "That's the story of another day, but if you are someone  who knows what the likelihood is, then you might want to skip this \"side track\" and get on the main track of discussing the AIC and BIC. But, I would like to build the intuition of it before continue with the examples. So, let's understand the likelihood.\n",
    "\n",
    "Huge thanks to [zstatistics](https://www.youtube.com/watch?v=ScduwntrMzc) video, which one is amazing explainer of all. If you want some more examples and a talk on the likelihood, please watch that out. Here, I will be taking reference from that and explaining what is needed for us to get goin'.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b44347-7b72-406d-b944-233a35783333",
   "metadata": {},
   "source": [
    "### üìú A Story.\n",
    "> Suppose we have taken a study in which picked up 2 sample groups and tried to find ***how many people are having a diabetese as a condition.*** We have found that \n",
    "> <br> <br> **Bhuj Group**: Out of 100, there is 7% chances of a person being diabetic. *(means, out of 100, there are 7 people with diabeties)*\n",
    "> <br> **Karnavati Group**: Out of 100, there is 8% chances of a person being diabetic. *(means, out of 100, there are 8 people with diabeties)*\n",
    "\n",
    "*(Bhuj & Karnavati are just the names of cities in Gujarat, India. They are chosen as the names of groups to make sense that the study is conducted in a real-life)* <br>\n",
    "That was the Story, now it comes to build a plot to work. So, let's continue with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88913ae-f981-461c-8c0b-e9e814b96d3b",
   "metadata": {},
   "source": [
    "### üñáÔ∏è A Plot.\n",
    "\n",
    "Since our team had an access to some statistical tools, they have made a **probability distribution plot** which could show the probabilities for all possible values. *(didn't get that? I know, you will get after having a look at the chart below)*\n",
    "\n",
    "<img src=\"../images/prob-7.png\" height=300 width=400>\n",
    "<img src=\"../images/prob-8.png\" height=300 width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d383f2-93c4-400f-b3aa-880a9b391aa7",
   "metadata": {},
   "source": [
    "There you can see that both of the plots are the probability distribution plots, meaning they *explore the probability of having `n` people diabities in the range of 0 to `N` based on the overall given probability*.\n",
    "\n",
    "So,\n",
    "- In the first plot, we can see that **the `7` has the highest probability of occuring**\n",
    "    - Interpret it as, *\"there is 0.02 probability of spotting 3 people as diabetic out of 100\"*\n",
    "    - Similarly, *\"there is 0.08 probability of spotting 10 people as diabetic out of 100\"*\n",
    "    - Finally, *\"there is 0.14 probability of spotting 7 people as diabetic out of 100\"*\n",
    "    - Thus, the 7 people having diabetic is the highest. And also can be seen that the number 6 is also having relatively high probability than others.\n",
    "- In the second plot, we can see that **the `8` has the highest probability of occuring**\n",
    "    - The probability for the number of people will change accordingly as now we are having a look at 8% plot\n",
    "    - Here also, 8 people having diabetic is the highest. And also can be seen that the number 7 is also having relatively high probability than others.\n",
    "    \n",
    "Are you still here? Yes? Good. Don't worry, this is simple plots. And the likelihood is not yet come."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90563b6-12fb-4b64-8ebc-77f1d44c5133",
   "metadata": {},
   "source": [
    "### ü™¢A Twist.\n",
    "The plot is ready. We have things we needed, now just we need to use them.\n",
    "\n",
    "> So let's say the team **picked up another 100 people from some place in India** and they have found that there are `6` people who are diabetic in the selected group.  <br>‚Äî<br>\n",
    "> Hence the question, **\"which group from our study is *the most LIKELY* to produce such results?\"**\n",
    "\n",
    "Man! The question just asked above is **of a likelihood**! But in the simple English! <br>\n",
    "So, in statistic jargon; we would ask:\n",
    "> *What is likelihood of Bhuj group given that 6 people being diabetic?*\n",
    "> <br>&<br>\n",
    "> *What is likelihood of Karnavati group given that 6 people being diabetic?*\n",
    "\n",
    "Yess. We will have to ask the questions to all groups that we have to get the answer. So, here who won? The group **Bhuj**. \n",
    "\n",
    "Why? <br>\n",
    "Because if we see the plots carefully, we will find that ***the probability of 6 people being diabetic is higher in the Bhuj group***.\n",
    "\n",
    "<img src=\"../images/prob-7_selected.png\" height=300 width=400>\n",
    "<img src=\"../images/prob-8_selected.png\" height=300 width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe993ab-125d-40cd-9c37-b6bdd0115508",
   "metadata": {},
   "source": [
    "And thus, ***the group Bhuj is the most likely to have 6 people as diabetic***. <br>\n",
    "And guyz, that's the story of Likelihood. The comparison that we saw is called \"Maximum Likelihood\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7651ea5-2e26-455c-80e4-3aaea6976946",
   "metadata": {},
   "source": [
    "### ü§î So, likelihood is finding the high probability?\n",
    "Yes! It is just the name given to \"the investigation of high probability\" to distinguish between them. Under-the-hood we are searching for the **distribution which has high probability of getting that thing done**.\n",
    "\n",
    "Thus, \n",
    "> **Probability**: Finding number for an event from given distribution ‚Äî $P(y | dist)$ <br>\n",
    "> **Likelihood**: Finding a distribution for given event ‚Äî $L(dist | y)$ \n",
    "\n",
    "The statements written above are for the intuition, please use them with care. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd909f45-44a0-4956-9b3c-a18aae535815",
   "metadata": {},
   "source": [
    "### üòØ Can we have all possibilities?\n",
    "Trying all possibilities and comparing by hand is a bit... tedious. Can we have a *function* that searches through all possibilities of the *distributions* and can comeup with the solution?\n",
    "\n",
    "Yes, **That's exactly what is called: likelihood function**.<br>\n",
    "Now you see that the jargons, the terms you have heard before, are nothing but the solutions of the problem. You were starting from Z and was getting confused *\"what the hack is this?\"* when you should have started from A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2730b929-9a9a-4aa0-9b7b-5e2f3a69f180",
   "metadata": {},
   "source": [
    "<img src=\"../images/likelihood_function.png\" width=300 height=400>\n",
    "\n",
    "That one is the likelihood function, *which has explored the likelihoods of all distributions for the `6` people being diabetic from 0 to 20 (as 0, 0.01, till 0.2 on the X-axis)*.\n",
    "\n",
    "Observations:\n",
    "- We can see that the peak that the function has found is at theta 0.06.\n",
    "- Which means, according to the function there should be a distribution wich has probability of 6 out of 100 *(of course)*.\n",
    "- Our Bhuj and Karnavati groups are also found in the chart as on 0.07 and 0.08 respectively and we can see that Karnavati group is having relatively low likelihood of including 6 people as diabetic than in the Bhuj group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5720d2-0f45-4b70-a7e2-1aa0fba6b35c",
   "metadata": {},
   "source": [
    "## Official definition of likelihood\n",
    "\n",
    "> *The likelihood describes the **extent** to which the sample **provides support** for any particular parameter value. Higher support corresponds to a higher value for the likelihood.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a90115-e627-434f-a9ae-4f0f046c2bed",
   "metadata": {},
   "source": [
    "- The exact value of the likelihood is **meaningless**\n",
    "- Meaning, just a single value will not help us to drive the point home, we need to **compare**.\n",
    "- That is obvious, and for that we use ***likelihood ratio***.\n",
    "\n",
    "#### Likelihood ratio\n",
    "\n",
    "## $$ \\frac{L(dist_1|y)}{L(dist_2|y)}$$\n",
    "\n",
    "___\n",
    "Example:\n",
    "\n",
    "‚Üí Bhuj Group had $0.152$ likelihood of having 6 people diabetic  <br>\n",
    "‚Üí Karnavati Group had $0.123$ likelihood of having 6 people diabetic \n",
    "\n",
    "So, the ratio will be:\n",
    "\n",
    "## $\\text{Likelihood Ratio} = \\frac{L(\\theta=dist_{\\text{with 7%}|y=6)}}{L(\\theta=dist_{\\text{with 8% }|y=6)}} = 1.124$\n",
    "\n",
    "> Thus, a *population prevalence* of `7%` has $1.124$ ***times the support*** of a *population prevalence* of `8%` *(given our sample)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6753a1e7-5d8c-4b06-a008-de890175d0ef",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4a88f-075b-4417-9976-c1a247ef1a87",
   "metadata": {},
   "source": [
    "## Likelihood function\n",
    "\n",
    "# $$ L(\\theta) = \\displaystyle\\prod_{i=1}^nP(y_i|\\theta)$$\n",
    "\n",
    "So, it turns out that **\"the likelihood is the *product* of individual outcomes\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3604d-f0d8-4c2c-8f70-3d735521f1ad",
   "metadata": {},
   "source": [
    "## Log - Likelihood function\n",
    "# $$ l(\\theta) = \\displaystyle\\sum_{i=1}^nlogP(y_i|\\theta)$$\n",
    "So, it turns out that **\"the log-likelihood is the *sum* of individual outcomes\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f5963-e607-4527-83f0-1898920d2972",
   "metadata": {},
   "source": [
    "### ü§® What happens inside?\n",
    "\n",
    "#### For Likelihood only (without Log)\n",
    "\n",
    "# $$L(\\theta|y)$$\n",
    "### $$‚Üì$$\n",
    "# $$P(y|\\theta)$$\n",
    "### $$‚Üì$$\n",
    "# $$^nC_y(\\theta)^y (1 - \\theta)^{n - y}$$\n",
    "\n",
    "So, for **Bhuj group**:\n",
    "\n",
    "## $^{100}C_6(0.07)^6 (1 - 0.07)^{100 - 6} = 0.152$\n",
    "\n",
    "So, for **Karnavati group**:\n",
    "\n",
    "## $^{100}C_6(0.08)^6 (1 - 0.08)^{100 - 6} = 0.123$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e68a2c-275e-4776-9f52-aa25051056fb",
   "metadata": {},
   "source": [
    "Given that, their ratio calculation will be:\n",
    "\n",
    "# $$\\frac{(\\theta_0)^6 (1-\\theta_0)^{100 - 6}}{(\\theta_1)^6 (1-\\theta_1)^{100 - 6}}$$\n",
    "\n",
    "Because, the $^{100}C_6$ from numerator and denominator will be cancelled.\n",
    "\n",
    "> **Note**: The similar thing happens with Log Likelihood but **instead of product** there, we **use the addition** and **instead of division** we use **subtraction**. So, I think that detail is unnecessary here. So skipping that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb069b9-9ffc-4d01-aa28-817ea485b774",
   "metadata": {},
   "source": [
    "# üõ§Ô∏è Out from the sidetrack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799f8924-2d64-4d34-9cda-1131251bc5e8",
   "metadata": {},
   "source": [
    "Finally, we have seen a glimpse of how the Likelihood works, though in a nutshell; there are also other things that can be stududied if you have time, but for now to go ahead, I think now I have privilage to include the word \"likelihood\" in my explanation and hopefully it will mean that we are on the same page üòÅ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
