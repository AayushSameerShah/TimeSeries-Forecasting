{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8424c334-7225-43ec-b318-52362a264a60",
   "metadata": {},
   "source": [
    "# üé≤ A Pholosophical Change in Perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4d61d-a7ea-4631-a867-ef52c0dbf05a",
   "metadata": {},
   "source": [
    "Before this point in time, we were used to discuss only about the ***ways*** to calculate the moving average. Now, it is the time to **forecast** points.\n",
    "\n",
    "For that, we will build up from what we have learnt so far *(EWMA)* and **use it instead of** calculating moving average but **to forecast**. That is gonna be awsome ‚Äî let's do that!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99172a20-93f4-41f0-9545-cf5c4eb7bae0",
   "metadata": {},
   "source": [
    "### Using new notations\n",
    "Till now we have:\n",
    "\n",
    "# $$ \\text{EWMA} = \\alpha x_t + (1 - \\alpha)\\bar x_{t - 1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dece8e-6be8-4183-a1ff-52c375d31884",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5708607-fec9-40fd-a704-f3c7077ad4b1",
   "metadata": {},
   "source": [
    "Just a little change as we are ***now forecasting***:\n",
    "\n",
    "# $$ \\hat y_t = \\alpha y_t + (1 - \\alpha)\\hat y_{t - 1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bcdec6-56a7-4d28-9afd-4c5bd7ef3ddd",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0540879-a510-4382-a1ca-58db72eef929",
   "metadata": {},
   "source": [
    "The ***official*** forecasting model:\n",
    "\n",
    "# $$ \\hat y_{t+1 | t} = \\alpha y_t + (1 - \\alpha)\\hat y_{t | t - 1}$$\n",
    "\n",
    "- $\\hat y_{t+1 | t}:$ The \"*future predicted*\" value of `t + 1` point ***given*** the current point `t`\n",
    "- $\\hat y_{t | t - 1}:$ The \"*current predictied*\" value of  `t` ***given*** the previous value of `t - 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a9827-526a-42f1-8427-bf5b732a37ab",
   "metadata": {},
   "source": [
    "This ‚Üë one, I know is not clear to me as well at this point in time `t` üòÖ but that will get clear as we will move forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656967ef-141b-4f49-b03a-9a38c2ef6fd9",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d1bcb-58f8-4e7f-90fd-03d5fb8aeace",
   "metadata": {},
   "source": [
    "Express our model **in the component** form:\n",
    "\n",
    "#### 1Ô∏è‚É£ Forecast Equation\n",
    "# $$\\hat y_{t + h | t} = l_t $$\n",
    "Where, <br>\n",
    "$h=1,2,3 ...$ \n",
    "<br>Meaning `t + h` th forecast in the future. Recall the `h` value from previous notebooks. `1. Timeseries Basics ‚Üí 4. Types of tasks ‚Üí 2.1 Incremental Forecast`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e106c32-bd47-4208-81da-4476610edf56",
   "metadata": {},
   "source": [
    "#### 2Ô∏è‚É£ Smoothing Equation\n",
    "# $$l_t = \\alpha y_t + (1 - \\alpha)l_{t - 1} $$\n",
    "\n",
    "Which, <br>\n",
    "is just the plugging the value of $l_t$ from 2Ô∏è‚É£ equation to the 1Ô∏è‚É£ equation. Might **not** make any sense now but here we are setting **THE LEVEL** which later add some other elements and building such habit will result smoother later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28806aa-e05d-45ac-aace-a2665aa44070",
   "metadata": {},
   "source": [
    "> **NOTE / NOTICE** that, the original indices are back when we **represent the equation** in the form of the component form ie. instead of writing $l_{t + 1 | t}$ we've just written $l_t$ as before under the section: \"*Just a little change as we are now forecasting*\" equation in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c2a45a-a0e3-436a-bc32-4652166ee581",
   "metadata": {},
   "source": [
    "# $l_t$ is the Level.\n",
    "This is the first time that we have been introduced in the ***jargons*** of the time-series. It is simple for now but then it will be more complex. Don't worry we will get there easily.\n",
    "\n",
    "The term **level** is first appeared at this path: `2. Exponential Smoothing and ETS ‚Üí 1. Moving and Exp` where we discussed that the level is the *constant* values around which the value of the time-series fluctuates. \n",
    "\n",
    "> Thus, **the level** can be thought of as the moving average which represents the mean of the fluctuations in that period.\n",
    "\n",
    "Here, in thsis simple SES, we will **only be able to predict** the mean fluctuation of the 1 step further in time because the value of `h` 2, 3, 4... will be just the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593cb12-9988-4493-91d2-8510de018085",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1295a4-997e-43d7-a750-891cc367c454",
   "metadata": {},
   "source": [
    "## üë®‚Äçüíª Great Goin'\n",
    "Let's now have a look at some code ‚Äî and this time we will be using `statsmodels`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1fbb93-fcb7-4859-9afa-d068b0fdedce",
   "metadata": {},
   "source": [
    "#### A Bit of Skeleton With Statsmodels\n",
    "Till now Aayush, you have worked with `sklearn` and used fit and predict. Here, the flow changes a bit. Let's have a look.\n",
    "\n",
    "```python\n",
    "# Model initialization \n",
    "model = someModel(param_1=0.1, param_2=\"euclidean\") # sklearn\n",
    "model = someModel(data) # statsmodels\n",
    "\n",
    "# Fitting\n",
    "model.fit(data) # sklearn\n",
    "model.fit(param_1=0.1, param_2=\"euclidean\") # statsmodels\n",
    "```\n",
    "See? Here in `statsmodels` the flow is a bit flipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a38cc7f-607d-499e-a9a4-b31dfec85e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is the model that we are going to work with\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3519436-66d9-493b-a9ae-1f8d30679f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers = pd.read_csv(\"../data/airline_passengers.csv\", index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81507d6-621f-4990-a60e-1ae5b99f6567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passengers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1949-01-01</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-02-01</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-03-01</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-04-01</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-05-01</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Passengers\n",
       "Month                 \n",
       "1949-01-01         112\n",
       "1949-02-01         118\n",
       "1949-03-01         132\n",
       "1949-04-01         129\n",
       "1949-05-01         121"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c7cdfb-ca10-4926-883e-6fef7dbfe645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "ses = SimpleExpSmoothing(passengers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a142a-494a-417b-ae41-f049c90322bb",
   "metadata": {},
   "source": [
    "So, you **see the warnings** right? They are telling that \"the model doesn't know that what frequency is there in the data\" meaning, is our data spread out monthly? weekly? yearly? 3 yearly? what?\n",
    "\n",
    "Thus, it *by default* takes the monthly. But in-case of other frequancy that we have in the data, we will need to pass them in the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc0b6b6-08b3-4a72-9411-f15f1ce09ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1949-01-01', '1949-02-01', '1949-03-01', '1949-04-01',\n",
       "               '1949-05-01', '1949-06-01', '1949-07-01', '1949-08-01',\n",
       "               '1949-09-01', '1949-10-01',\n",
       "               ...\n",
       "               '1960-03-01', '1960-04-01', '1960-05-01', '1960-06-01',\n",
       "               '1960-07-01', '1960-08-01', '1960-09-01', '1960-10-01',\n",
       "               '1960-11-01', '1960-12-01'],\n",
       "              dtype='datetime64[ns]', name='Month', length=144, freq=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See that the frequency is NONE\n",
    "passengers.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f3c0c5b-a4d6-42fa-be6d-5d9bad98c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try setting \"D\", \"Y\" etc... but that will result an error as it will\n",
    "# check that `really` the frequancy is there or not, so better to use the  correct one\n",
    "passengers.index.freq = \"MS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8124cd4d-1e0d-4ff0-8a65-6211fbe0cd7a",
   "metadata": {},
   "source": [
    "Here `MS` means **Month Start** and the `M` means **Month End**. So, keep that in mind. Or just refer your [Time in Pandas](https://github.com/AayushSameerShah/Pandas_Book/tree/main/2.%20Pandas/6.%20TIME) repository!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e50506b-300e-480c-a151-314a8f62ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again need to put the data in to reflect the `freq` change\n",
    "ses = SimpleExpSmoothing(passengers,\n",
    "                        initialization_method=\"legacy-heuristic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c5824-331c-4575-b8de-049ac42df28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
