{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64edd0b-8596-4315-a4aa-79706d3148f1",
   "metadata": {},
   "source": [
    "# üê• Chosen points for models\n",
    "Since I have started this section assuming the reader's background in mind, I am not explaining the models here. Instead, here I will *point* the *points* which I think are new and should be read once per model.\n",
    "\n",
    "So, this notebook will contain the notes on the topic \"*about ML models*\" instead of \"*how ML models*\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a47fe9-4504-40d5-b782-72f7b593dfb9",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4668ddf-4e4f-4f7c-8350-f34d09e87c2e",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Linear Regression \n",
    "- Not a good fit when the relationship is non-linear (obvious)\n",
    "- Don't think ML as \"math\" ‚Äî think as a **pattern**\n",
    "- Many models follow the *linear regression like* formulae (like neural networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cba0f6-aa52-4748-9997-22a25e0595b8",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Logistic Regression\n",
    "- A classification analogue of linear regression\n",
    "> ***analogue:** something that is similar or comparable to something else either in general or in some specific detail*.\n",
    "- Why **can't** we just use **linear regression**?\n",
    "    - Technically we can, but not ideal.\n",
    "    - Linear regression assumes that the predictions are gaussian\n",
    "    - In classification, it is binary. So, it follows the Bernoulli distribution. \n",
    "- Uses the sigmoid function. Maps the real numbers into probabilities.\n",
    "- In binary problems we **round** the probability\n",
    "- In multiclass, we use **argmax** (as rounding won't make sense)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cefcea-ccf3-4d65-af5e-59d7e1ef4fe0",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Support Vector Machines\n",
    "- A model based ***completely*** on geometry.\n",
    "- We can also introduce the slack variables in the real world situations where the real-perfect seperation is not possible.\n",
    "- Slack variables are those which are allowed by the model to be misclassified.\n",
    "- SVM are picked up over LinReg ot LogReg is because of their **kernel trick**.\n",
    "    - It is the feature engineering\n",
    "    - Producing new features to make a linear model to be used as non linear\n",
    "    - I have read about this in the \"Data Science Handbook\" book (also in my Git Repository)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786564c-1e6b-4c90-9c70-9370715d4309",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Random Forest\n",
    "- The most popular and a \"go-to\" method for any ML task\n",
    "- Unlike deep neural networks it doesn't require any manual creation of the architecture of the model.\n",
    "- *\"A bunch of trees voting together\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c167c91c-44c7-4836-8d49-6afe511131b0",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e3170d-3469-48ca-bcd6-50e8113d9a6b",
   "metadata": {},
   "source": [
    "# I think we are done.\n",
    "And wo..woo... you have just learnt how ML works! Hah. So, in the next book we will take a look at how do they applied. And that is the main part.\n",
    "\n",
    "See you there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
