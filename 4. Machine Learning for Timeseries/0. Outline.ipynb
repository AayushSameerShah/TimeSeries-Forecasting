{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0494c3c-6849-40c1-a54b-a75915c4aa1d",
   "metadata": {},
   "source": [
    "# ðŸ’– Getting in the \"known zone\"\n",
    "This is the \"**Time-series with Machine Learning**\" section. Here we will use our *known* models such as *Linear Regression*, *Logistic Regression*, *Random Forest* etc for the time-series!\n",
    "\n",
    "I mean â€” they aren't *exactly* made up for the time-series but since the models like ARIMA use Linear Regression *like* structure inside, why can't other models get a try? Makes sense? I think that was a a **biggest** hint of this section! (ðŸ˜„)\n",
    "\n",
    "Let's do some discussion on this section and then start coding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3271a6d8-8b42-4ba1-9a0b-7db66ba3a09d",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0200089-a11d-41e9-9209-7a227c298992",
   "metadata": {},
   "source": [
    "## ðŸ¤” Why is Machine Learning different?\n",
    "The statement that given above *(hidden one)* can be debatable, or argueable. That \"this is the ML section and the ML models will be used for Time-series\". \n",
    "\n",
    "Simply that statement can raise the arguement that: *\"if the time-series is not a part of ML then ML should be different...\"*. This discussion is carried out **very heavily** but also in the funny manner by the author in the course so I am not pointing them here but the main idea to take home is that *(in author's words)*:\n",
    "\n",
    "> *\"Keep in mind that, what is and what isn't machine learning **is just a subject of opinion**. At the end of the day if you understand how these things work, what you call it is irrelevant.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afb04ab-9f5a-494a-a290-5e491429ecc4",
   "metadata": {},
   "source": [
    "I agree with his statement. And I loved the way he presented the so-called \"definition\" of the ML that we read today on the internet like: *\"ML is a field where computers learn by themselves without being explicitly programmed...\"* \n",
    "\n",
    "That's right and from his POV, machine learning is **geometry**; and he continues with the example. They are not the point of this notebook or to get the concept in mind. So I am not discussing them here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53362990-b223-4603-98d8-787da4b3b3d8",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a68b3-8164-464d-9641-48d4253f6646",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ The goals of this section \n",
    "- Here we will focus on understanding what problems ML can solve and **how to convert time-series problems into standard ML problems**.\n",
    "\n",
    "*(That means, when we will get the models' discussion, we won't get into the details of how they work, but instead we will understand how they can be applied for time-series.)*\n",
    "\n",
    " And ***also***: This methods will be \"Model-Agnositc\". <br> \n",
    "Meaning, whichever model we use â€” method will be the same. The method is the framework (much like RegressorChain or SimpleTarget in MTR that you are exploring now a days ðŸ˜‰)\n",
    "\n",
    "- We will also see the **Regression** and **Classification** scenario with Time-series!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d5e93-a2cb-4c57-b82b-7b2473a0b061",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de733c-0c64-438e-b47a-fc32f9ff8fa4",
   "metadata": {},
   "source": [
    "## âž° An also, a term \"Self-Supervised\" \n",
    "Since, I have already given you the **hint** that whatever that we ate going to do is **to transform the problem** into a time-series problem. If you recall, the *general* format of the ML approach is to have a tabular structure like:\n",
    "\n",
    "<img src=\"../images/supervised.png\" height=300 width=400>\n",
    "\n",
    "So, from that we will **transform** our time-series data into the same looking strucutre so that it can be accepted by the ML model.\n",
    "\n",
    "<img src=\"../images/time-series-transformation.png\" height=300 width=400>\n",
    "\n",
    "Like that. <br>\n",
    "Looks familiar? It is! <br>\n",
    "\n",
    "> And exactly for that I gave you the hint for! That's what we did in the AR(p) model.\n",
    "\n",
    "***And that, that my boy; is called <u>Self-Supervised</u> learning***.\n",
    "\n",
    "- The advantage is that: *it allows us to learn from the data, without requiring the label!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c31090-c758-41d4-b463-e74bdcd50fe1",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25336ec-764d-4b20-bd58-be1208b1ffb7",
   "metadata": {},
   "source": [
    "## ðŸ¤ A Small Reminder\n",
    "* A reminder that I forgot to give when we were dealing with ARIMA model.\n",
    "* A reminder that I should have discussed there, but still while realizing now, I am getting lazy to update there.\n",
    "* A reminder for which we have discussed in the first section of this course\n",
    "\n",
    "> It is the *multi-step forecasting problem*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49da096f-c2d9-43da-a89e-85aa74623cca",
   "metadata": {},
   "source": [
    "Aah! Suddently some flashback, so many memories, a word that you saw before your infancy... kind of those feelings? Don't worry.\n",
    "\n",
    "We used that word for the very first time in the first section where we discussed **types of forecast**. There we saw 2 types in general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9e7a8d-d490-4ec8-b6f4-52d6f1ba2039",
   "metadata": {},
   "source": [
    "> 1. **One-Step**\n",
    "2. **Multi-Step**\n",
    "     - Incremental Multi-step\n",
    "     - Multi-output Multi step\n",
    "3. **Time series classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d43fae-1bb7-4cbf-bc6a-65b68568fa79",
   "metadata": {},
   "source": [
    "So, it is the `2nd type â€” Multi-step` and the Incremental Multi-step to be specific. It is where we **use the prediction from the past model as an input of the current model**.\n",
    "\n",
    "___\n",
    "The new term to learn is ***\"error propogation\"***.\n",
    "- That means, we make the prediction and then use it as an input of the next model\n",
    "- So, in the prediction there **has to be some error**.\n",
    "- Thus, the errors get counted in the upcoming models.\n",
    "- The errors are **compounded** over each steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f949e-c9c3-480d-b8cb-60242d9c0f03",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc34e3-3bf5-4dd9-8e84-a7c923758139",
   "metadata": {},
   "source": [
    "# Aw, that wasn't an outline!\n",
    "ðŸ˜‚ I know, a lot of things discussed in the outline book. But I had to, the things were simple and we generally know them. With that we can know what is coming in this section. I am a little excited to learn new.\n",
    "\n",
    "Let's see what is that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
